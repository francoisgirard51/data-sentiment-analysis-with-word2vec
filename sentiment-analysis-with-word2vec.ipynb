{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with Word2Vec\n",
    "\n",
    "### Exercise objectives:\n",
    "- Convert words to vectors with Word2Vec\n",
    "- Use the word representation given by Word2vec to feed a RNN\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ñ∂Ô∏è Run this cell and make sure the version of üìö [Gensim - Word2Vec](https://radimrehurek.com/gensim/auto_examples/index.html) you are using is ‚â• 4.0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim==4.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Let's first load the data. You don't have to understand what is going on in the function, it does not matter here.\n",
    "\n",
    "‚ö†Ô∏è **Warning** ‚ö†Ô∏è The `load_data` function has a `percentage_of_sentences` argument. Depending on your computer, there are chances that too many sentences will make your compute slow down, or even freeze - your RAM can overflow. For that reason, **you should start with 10% of the sentences** and see if your computer handles it. Otherwise, rerun with a lower number. \n",
    "\n",
    "‚ö†Ô∏è **DISCLAIMER** ‚ö†Ô∏è **No need to play _who has the biggest_ (RAM) !** The idea is to get to run your models quickly to prototype. Even in real life, it is recommended that you start with a subset of your data to loop and debug quickly. So increase the number only if you are into getting the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 15:59:17.514916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77c71174ee44b33a71ec1fd4fd6d3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0283cf6f099447fb3d2281adc07bb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete1FZC0M/imdb_reviews-train.tfrecord*...‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete1FZC0M/imdb_reviews-test.tfrecord*...:‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete1FZC0M/imdb_reviews-unsupervised.tfrec‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 16:00:37.707588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### Just run this cell to load the data ###\n",
    "###########################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "  \n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "    \n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you trained a Word2vec representation and converted all your training sentences in order to feed them into a RNN, as shown in the first step of this Figure: \n",
    "\n",
    "<img src=\"word2vec_representation.png\" width=\"400px\" />\n",
    "\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Here, let's re-do exactly what you have done in the previous exercise. First, train a word2vec model (with the arguments that you want) on your training sentence. Store it into the `word2vec` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Define Word2Vec parameters\n",
    "vector_size = 100  # Size of the word vectors\n",
    "window = 5         # Context window size\n",
    "min_count = 5      # Minimum word count to include a word in the vocabulary\n",
    "\n",
    "# Train the Word2Vec model\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=vector_size, window=window, min_count=min_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reuse the functions of the previous exercise to convert your training and test data into something you can feed into a RNN.\n",
    "\n",
    "‚ùì **Question** ‚ùì Read the following function to be sure you understand what is going on, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è To be sure that it worked, let's check the following for `X_train_pad` and `X_test_pad`:\n",
    "- they are numpy arrays\n",
    "- they are 3-dimensional\n",
    "- the last dimension is of the size of your word2vec embedding space (you can get it with `word2vec.wv.vector_size`\n",
    "- the first dimension is of the size of your `X_train` and `X_test`\n",
    "\n",
    "‚úÖ **Good Practice** ‚úÖ Such tests are quite important! Not only in this exercise, but in real-life applications. It prevents from finding errors too late and from letting them propagate through the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ME\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "It is always good to have a very simple model to test your own model against - to be sure you are doing something better than a very simple algorithm.\n",
    "\n",
    "‚ùì **Question** ‚ùì What is your baseline accuracy? In this case, your baseline can be to predict the label that is the most present in `y_train` (of course, if the dataset is balanced, the baseline accuracy is 1/n where n is the number of classes - 2 here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.506\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Count the frequency of each label in y_train\n",
    "label_counts = Counter(y_train)\n",
    "\n",
    "# Find the most common label\n",
    "most_common_label, most_common_count = label_counts.most_common(1)[0]\n",
    "\n",
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = most_common_count / len(y_train)\n",
    "\n",
    "print(\"Baseline Accuracy:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "‚ùì **Question** ‚ùì Write a RNN with the following layers:\n",
    "- a `Masking` layer\n",
    "- a `LSTM` with 20 units and `tanh` activation function\n",
    "- a `Dense` with 10 units\n",
    "- an output layer that depends on your task\n",
    "\n",
    "Then, compile your model (we advise you to use the `rmsprop` as the optimizer - at least to begin with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_1 (Masking)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                9680      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,901\n",
      "Trainable params: 9,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "\n",
    "# Assuming you know the embedding size (e.g., 100 for Word2Vec embeddings)\n",
    "embedding_size = 100\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Masking layer\n",
    "model.add(Masking(mask_value=0.0, input_shape=(None, embedding_size)))  # Specify the input shape\n",
    "\n",
    "# Add an LSTM layer with 20 units and tanh activation\n",
    "model.add(LSTM(20, activation='tanh'))\n",
    "\n",
    "# Add a Dense layer with 10 units\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Add an output layer for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Now, the model summary should work\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Fit the model on your embedded and padded data - do not forget the early stopping criterion.\n",
    "\n",
    "‚ùó **Remark** ‚ùó Your accuracy will greatly depend on your training corpus. Here just make sure that your performance is above the baseline model (which should be the case even if you loaded only 20% of the initial IMDB data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 14s 114ms/step - loss: 0.6928 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5304\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 7s 94ms/step - loss: 0.6800 - accuracy: 0.5708 - val_loss: 0.6825 - val_accuracy: 0.5624\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 7s 93ms/step - loss: 0.6637 - accuracy: 0.5964 - val_loss: 0.6705 - val_accuracy: 0.5872\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 8s 95ms/step - loss: 0.6471 - accuracy: 0.6208 - val_loss: 0.6644 - val_accuracy: 0.6024\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 7s 94ms/step - loss: 0.6397 - accuracy: 0.6396 - val_loss: 0.6513 - val_accuracy: 0.6212\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 7s 92ms/step - loss: 0.6282 - accuracy: 0.6464 - val_loss: 0.6590 - val_accuracy: 0.6092\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 7s 93ms/step - loss: 0.6230 - accuracy: 0.6524 - val_loss: 0.6469 - val_accuracy: 0.6256\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 8s 95ms/step - loss: 0.6014 - accuracy: 0.6788 - val_loss: 0.6903 - val_accuracy: 0.5712\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 7s 93ms/step - loss: 0.5975 - accuracy: 0.6844 - val_loss: 0.6282 - val_accuracy: 0.6548\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 7s 93ms/step - loss: 0.5898 - accuracy: 0.7000 - val_loss: 0.6382 - val_accuracy: 0.6336\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 7s 95ms/step - loss: 0.5786 - accuracy: 0.6980 - val_loss: 0.6736 - val_accuracy: 0.6172\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 7s 92ms/step - loss: 0.5681 - accuracy: 0.7168 - val_loss: 0.6230 - val_accuracy: 0.6568\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 7s 95ms/step - loss: 0.5638 - accuracy: 0.7200 - val_loss: 0.6515 - val_accuracy: 0.6616\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 7s 94ms/step - loss: 0.5591 - accuracy: 0.7192 - val_loss: 0.6782 - val_accuracy: 0.6268\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 7s 94ms/step - loss: 0.5456 - accuracy: 0.7252 - val_loss: 0.7402 - val_accuracy: 0.5916\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 7s 94ms/step - loss: 0.5398 - accuracy: 0.7340 - val_loss: 0.6313 - val_accuracy: 0.6568\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=20,  # You can adjust the number of epochs\n",
    "                    validation_data=(X_test_pad, y_test),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Check the training history (e.g., accuracy)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Evaluate your model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 19ms/step - loss: 0.6313 - accuracy: 0.6568\n",
      "Test Loss: 0.6313245892524719\n",
      "Test Accuracy: 0.6567999720573425\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained Word2Vec - Transfer Learning\n",
    "\n",
    "Your accuracy, while above the baseline model, might be quite low. There are multiple options to improve it, as data cleaning and improving the quality of the embedding.\n",
    "\n",
    "We won't dig into data cleaning strategies here. Let's try to improve the quality of our embedding. But instead of just loading a larger corpus, why not benefiting from the embedding that others have learned? Because, the quality of an embedding, i.e. the proximity of the words, can be derived from different tasks. This is exactly what transfer learning is.\n",
    "\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì List all the different models available in the word2vec thanks to this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "print(list(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è You can also find the list of the models and their size on the [`gensim-data` repository](https://github.com/RaRe-Technologies/gensim-data#models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Load one of the pre-trained word2vec embedding spaces. \n",
    "\n",
    "You can do that with `api.load(the-model-of-your-choice)`, and store it in `word2vec_transfer`\n",
    "\n",
    "<details>\n",
    "    <summary>üí° Hint</summary>\n",
    "    \n",
    "The `glove-wiki-gigaword-50` model is a good candidate to start with as it is smaller (65 MB).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pre-trained \"glove-wiki-gigaword-50\" model\n",
    "word2vec_transfer = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Check the size of the vocabulary, but also the size of the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 400000\n",
      "Size of Embedding Space: 50\n"
     ]
    }
   ],
   "source": [
    "# Size of the vocabulary\n",
    "vocab_size_transfer = len(word2vec_transfer.key_to_index)\n",
    "print(\"Vocabulary Size:\", vocab_size_transfer)\n",
    "\n",
    "# Size of the embedding space (dimensionality of word vectors)\n",
    "# We can take any word's vector to find this out\n",
    "any_word = list(word2vec_transfer.key_to_index.keys())[0]\n",
    "embedding_size_transfer = len(word2vec_transfer[any_word])\n",
    "print(\"Size of Embedding Space:\", embedding_size_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's embed `X_train` and `X_test`, same as in the first question where we provided the functions to do so! (There is a slight difference in the `embed_sentence_with_TF` function that we will not dig into)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì  Do not forget to pad your results and store it in `X_train_pad_2` and `X_test_pad_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def pad_embedded_sequences(embedded_sequences, maxlen=None):\n",
    "    \"\"\"Pad embedded sequences to have the same length.\"\"\"\n",
    "    # Find the maximum length of any sentence (if not provided)\n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(seq) for seq in embedded_sequences)\n",
    "    \n",
    "    # Pad each sequence to have the same length\n",
    "    padded_sequences = np.zeros((len(embedded_sequences), maxlen, embedded_sequences[0].shape[1]))\n",
    "    for i, seq in enumerate(embedded_sequences):\n",
    "        if len(seq) != 0:\n",
    "            padded_sequences[i, :len(seq)] = seq[:maxlen]\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "# Determine the max length (you can set this manually to a fixed number if needed)\n",
    "max_len_train = max(len(seq) for seq in X_train_embed_2)\n",
    "max_len_test = max(len(seq) for seq in X_test_embed_2)\n",
    "max_len = max(max_len_train, max_len_test)\n",
    "\n",
    "# Pad the embedded sequences\n",
    "X_train_pad_2 = pad_embedded_sequences(X_train_embed_2, maxlen=max_len)\n",
    "X_test_pad_2 = pad_embedded_sequences(X_test_embed_2, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Reinitialize a model and fit it on your new embedded (and padded) data!  Evaluate it on your test set and compare it to your previous accuracy.\n",
    "\n",
    "‚ùó **Remark** ‚ùó The training here could take some time. You can just compute 10 epochs (this is **not** a good practice, it is just not to wait too long) and go to the next exercise while it trains - or take a break, you probably deserve it ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 50s 557ms/step - loss: 0.6747 - accuracy: 0.5720 - val_loss: 0.6464 - val_accuracy: 0.6336\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 0.6394 - accuracy: 0.6472 - val_loss: 0.6329 - val_accuracy: 0.6388\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 0.6402 - accuracy: 0.6292 - val_loss: 0.6510 - val_accuracy: 0.6492\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 0.6103 - accuracy: 0.6700 - val_loss: 0.5866 - val_accuracy: 0.7012\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 0.5912 - accuracy: 0.6888 - val_loss: 0.5810 - val_accuracy: 0.7084\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 0.6021 - accuracy: 0.6808 - val_loss: 0.5801 - val_accuracy: 0.7036\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 0.5727 - accuracy: 0.7040 - val_loss: 0.6271 - val_accuracy: 0.6692\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 0.5665 - accuracy: 0.7108 - val_loss: 0.5823 - val_accuracy: 0.7032\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 0.5498 - accuracy: 0.7232 - val_loss: 0.5401 - val_accuracy: 0.7400\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 0.5333 - accuracy: 0.7368 - val_loss: 0.5271 - val_accuracy: 0.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e35b7c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinitialize the model with the correct input shape\n",
    "model_2 = Sequential()\n",
    "model_2.add(Masking(mask_value=0.0, input_shape=(X_train_pad_2.shape[1], 50)))  # Adjust the second dimension to match the embedding size of the pre-trained model\n",
    "model_2.add(LSTM(20, activation='tanh'))\n",
    "model_2.add(Dense(10, activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "model_2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(X_train_pad_2, y_train, epochs=10, validation_data=(X_test_pad_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nSpecified a list with shape [?,100] from a tensor with shape [32,50]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_1/lstm_1/PartitionedCall]] [Op:__inference_test_function_37640]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_pad_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe accuracy evaluated on the test set is of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nSpecified a list with shape [?,100] from a tensor with shape [32,50]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_1/lstm_1/PartitionedCall]] [Op:__inference_test_function_37640]"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X_test_pad_2, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because your new word2vec has been trained on a large corpus, it has a representation for many many words! Way more than with your small dataset, especially as you discarded words that were not present more than a given number of times in the train set. For that reason, you have way more embedded words in your train and test set, which makes each iteration longer than previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
